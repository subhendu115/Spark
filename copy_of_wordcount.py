# -*- coding: utf-8 -*-
"""Copy of wordCount.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OMrETbjmUN5XsPIVqfAAaAST1fndz9uC
"""

pip install pyspark

"""# **WordCount Example using PySpark DataFrame**"""

from pyspark.sql import SparkSession

from pyspark.sql.types import StructType,StructField, StringType

from pyspark.sql.functions import col,explode,split

spark = SparkSession.builder.master("local[*]").appName("test").getOrCreate()

schema = StructType([StructField("text",StringType(),True)])

df = spark.read.option("header",True).csv("sample_data/README.md",schema=schema)

df.show(truncate=False)

df.select(explode(split(col("text")," "))).groupBy("col").count().show()

"""# **Word Count using PySpark RDD**"""

sc = spark.sparkContext

words = sc.textFile("sample_data/README.md").flatMap(lambda line:line.split(" "))

wordCount = words.map(lambda word:(word,1)).reduceByKey(lambda a,b:a+b)

wordCount.take(100)

